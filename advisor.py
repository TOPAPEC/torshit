from wiki import WikiService
from embeddings import EmbeddingService
from llm import LLMService
from seasons import SEASONS
from activities import ActivityMatcher
from temperature import normalize_temperature_text, is_temperature_in_range
from config import Config
import re
import json
import asyncio

class TravelAdvisor:
    def __init__(self, model_context_length: int = 10000):
        print("Initializing TravelAdvisor")
        self.wiki_service = WikiService()
        self.embedding_service = EmbeddingService()
        self.llm_service = LLMService(model_context_length)
        self.context_manager = self.llm_service.context_manager
        self.activity_matcher = ActivityMatcher(self.llm_service)
        
        # Load tourist facts
        with open('tourist_facts.json', 'r', encoding='utf-8') as f:
            self.tourist_facts = json.load(f)
        
        # Calculate embeddings for all facts using batching
        from tqdm import tqdm
        self.fact_embeddings = {}
        
        # Count total facts for progress bar
        total_facts = sum(
            len(facts) 
            for categories in self.tourist_facts.values() 
            for facts in categories.values()
        )
        print(f"Found {total_facts} facts to process")
        
        # Collect all facts with progress bar
        all_facts = []
        fact_to_city_category = {}
        with tqdm(total=total_facts, desc="Collecting facts") as pbar:
            for city, categories in self.tourist_facts.items():
                for category, facts in categories.items():
                    for fact in facts:
                        all_facts.append(fact)
                        fact_to_city_category[fact] = (city, category)
                        pbar.update(1)
        
        # Get embeddings in batches
        print("Computing embeddings...")
        fact_embeddings = self.embedding_service.get_embeddings_batch(all_facts)
        
        # Organize embeddings back into structure
        print("Organizing results...")
        for fact, embedding in fact_embeddings.items():
            city, category = fact_to_city_category[fact]
            if city not in self.fact_embeddings:
                self.fact_embeddings[city] = {}
            if category not in self.fact_embeddings[city]:
                self.fact_embeddings[city][category] = []
            self.fact_embeddings[city][category].append((fact, embedding))
        
    def _filter_cities_by_season(self, cities_content: dict, season: str, preferences: str = "") -> dict:
        """Filter cities based on seasonal criteria and preferences"""
        if not season:
            return cities_content
            
        filtered_cities = {}
        season_data = SEASONS[season]
        
        # Extract temperature preference if specified
        temp_pref = None
        if "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞:" in preferences.lower():
            temp_match = re.search(r'—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞:.*?(\d+)', preferences.lower())
            if temp_match:
                temp_pref = int(temp_match.group(1))
        
        for city, content in cities_content.items():
            city_text = content.summary.lower()
            matches_season = False
            city_temps = []
            
            # Extract all temperatures
            temp_matches = re.finditer(r'—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞.*?(-?\d+)', city_text)
            for match in temp_matches:
                temp = int(match.group(1))
                city_temps.append(temp)
            
            # Check seasonal temperature ranges
            if city_temps:
                avg_temp = sum(city_temps) / len(city_temps)
                if season_data['temp_range'][0] <= avg_temp <= season_data['temp_range'][1]:
                    matches_season = True
                    
                    # Apply temperature preference if specified
                    if temp_pref and any(temp > temp_pref for temp in city_temps):
                        matches_season = False
            
            # Check for required infrastructure based on preferences, but be more lenient for beach cities
            if city not in Config.RESORT_CITIES.get('–º–æ—Ä–µ', []):  # Only apply strict checks for non-beach cities
                if '—Å–ø–∞' in preferences.lower() or '–º–∞—Å—Å–∞–∂' in preferences.lower():
                    if not any(kw in city_text.lower() for kw in ['—Å–ø–∞', '–º–∞—Å—Å–∞–∂', '–≤–µ–ª–Ω–µ—Å', 'wellness', '—Å–∞–Ω–∞—Ç–æ—Ä–∏']):
                        continue
                        
                if '–∞–∫–≤–∞–ø–∞—Ä–∫' in preferences.lower():
                    if not any(kw in city_text.lower() for kw in ['–∞–∫–≤–∞–ø–∞—Ä–∫', '–≤–æ–¥–Ω—ã–µ –∞—Ç—Ç—Ä–∞–∫—Ü–∏–æ–Ω', '—Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏—è']):
                        continue
                    
            # Check for seasonal activities and infrastructure
            if any(keyword in city_text for keyword in season_data['keywords']):
                matches_season = True
                
            # Additional winter sports check with expanded keywords
            if season == 'winter' and '–≥–æ—Ä–Ω–æ–ª—ã–∂' in preferences.lower():
                if not any(kw in city_text.lower() for kw in [
                    '–≥–æ—Ä–Ω–æ–ª—ã–∂', '–ª—ã–∂', '–ø–æ–¥—ä–µ–º–Ω–∏–∫', '—Ç—Ä–∞—Å—Å', '—Å–∫–ª–æ–Ω', 
                    '–∫–∞—Ç–∞–Ω–∏', '—Å–Ω–æ—É–±–æ—Ä–¥', '–≥–æ—Ä–Ω–æ–ª—ã–∂–Ω—ã–π –∫—É—Ä–æ—Ä—Ç'
                ]):
                    matches_season = False
                    
            # Additional summer beach check with expanded criteria   
            if season == 'summer' and '–ø–ª—è–∂' in preferences.lower():
                # For beach cities, be more lenient with seasonal matching
                if city in Config.RESORT_CITIES.get('–º–æ—Ä–µ', []):
                    matches_season = True
                else:
                    beach_keywords = ['–ø–ª—è–∂', '–º–æ—Ä–µ', '–ø–µ—Å—á', '–∫—É—Ä–æ—Ä—Ç', '–Ω–∞–±–µ—Ä–µ–∂–Ω', '–ø–æ–±–µ—Ä–µ–∂', '–∑–∞–ª–∏–≤', '–±—É—Ö—Ç']
                    infra_keywords = ['—Ä–∞–∑–≤–ª–µ—á–µ–Ω', '–∞–∫–≤–∞–ø–∞—Ä–∫', '–∞—Ç—Ä–∞–∫—Ü–∏–æ–Ω', '–¥–µ—Ç—Å–∫–∞—è –ø–ª–æ—â–∞–¥–∫–∞', '–æ—Ç–¥—ã—Ö']
                    
                    has_beach = any(kw in city_text.lower() for kw in beach_keywords)
                    has_infrastructure = '—Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–ª—è –¥–µ—Ç–µ–π' not in preferences.lower() or \
                                       any(kw in city_text.lower() for kw in infra_keywords)
                    
                    if has_beach:  # Only require beach presence for summer season
                        matches_season = True
            
            if matches_season:
                filtered_cities[city] = content
        
        # If no cities match criteria, try relaxing constraints before returning original
        if not filtered_cities:
            # Try matching just keywords without temperature
            for city, content in cities_content.items():
                if any(keyword in content.summary.lower() for keyword in season_data['keywords']):
                    filtered_cities[city] = content
                    
        return filtered_cities if filtered_cities else cities_content

    async def process_request(self, user_input: str):
        try:
            # Extract preferences and season
            preferences = await self.llm_service.get_preferences(user_input)
            print(f"Extracted preferences: {preferences}")
            
            # Extract activities and season
            activities = await self.activity_matcher.get_activities(user_input + "\n" + preferences)
            if activities:
                print(f"üéØ Detected activities: {', '.join(f'{act}({conf:.2f})' for act, conf in activities)}")
            
            season = await self.llm_service.get_season(user_input + "\n" + preferences)
            if season:
                print(f"üåç Detected season: {season}")
                
            # Store primary activity for ranking
            primary_activity = activities[0][0] if activities else None

            # Calculate available tokens
            available_tokens = self.context_manager.get_available_tokens(preferences, is_rag=True)
            print(f"Available tokens: {available_tokens}")

            # Determine location type from preferences and activities
            location_type = None
            pref_text = preferences.lower()
            
            # Check for beach/sea indicators
            if any(word in pref_text for word in ['–ø–ª—è–∂', '–º–æ—Ä–µ', '–ø–µ—Å–æ–∫', '–ø–ª—è–∂–Ω—ã–π –æ—Ç–¥—ã—Ö']):
                location_type = '–º–æ—Ä–µ'
            # Check for mountain/skiing indicators    
            elif any(word in pref_text for word in ['–≥–æ—Ä—ã', '–ª—ã–∂', '–≥–æ—Ä–Ω–æ–ª—ã–∂']):
                location_type = '–≥–æ—Ä—ã'
            # Check for spa/wellness indicators
            elif any(word in pref_text for word in ['—Å–ø–∞', '—Å–∞–Ω–∞—Ç–æ—Ä–∏', '–æ–∑–¥–æ—Ä–æ–≤–∏—Ç–µ–ª—å–Ω', '–ª–µ—á–µ–±–Ω', '–º–∞—Å—Å–∞–∂']):
                location_type = 'spa'
            # Check for city/cultural indicators
            elif any(word in pref_text for word in ['–º—É–∑–µ–π', '–∫—É–ª—å—Ç—É—Ä', '–≥–æ—Ä–æ–¥', '–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä']):
                location_type = '–≥–æ—Ä–æ–¥'
            
            # Also check activities
            if activities:
                activity = activities[0][0]
                if activity in ['beach_vacation', 'water_sports']:
                    location_type = '–º–æ—Ä–µ'
                elif activity in ['winter_sports', 'skiing']:
                    location_type = '–≥–æ—Ä—ã'
                elif activity in ['cultural_tourism', 'city_break']:
                    location_type = '–≥–æ—Ä–æ–¥'
            
            print(f"Determined location type: {location_type}")
            cities_content = await self.wiki_service.get_cities_by_type(location_type) if location_type else await self.wiki_service.get_all_cities_content()
            
            if not cities_content:
                print("No cities content found")
                return None, None, None, None, None

            # Normalize temperature data
            normalized_cities = {}
            for city, content in cities_content.items():
                content.summary = normalize_temperature_text(content.summary)
                normalized_cities[city] = content
            cities_content = normalized_cities
            
            # Enhanced activity filtering with infrastructure requirements
            if primary_activity:
                filtered_cities = {}
                for city, content in cities_content.items():
                    activity_score = self.activity_matcher.get_activity_score(content.summary, primary_activity)
                    city_text = content.summary.lower()
                    
                    # Use a lower threshold for beach_vacation to be more inclusive
                    min_score = 0.1 if primary_activity == 'beach_vacation' else 0.2
                    
                    if activity_score >= min_score:
                        # For beach_vacation, check if it's in the –º–æ—Ä–µ category or has beach-related keywords
                        if primary_activity == 'beach_vacation':
                            beach_keywords = ['–ø–ª—è–∂', '–º–æ—Ä–µ', '–ø–æ–±–µ—Ä–µ–∂', '–∑–∞–ª–∏–≤', '–±—É—Ö—Ç', '–∫—É—Ä–æ—Ä—Ç']
                            if city in Config.RESORT_CITIES.get('–º–æ—Ä–µ', []) or any(kw in city_text for kw in beach_keywords):
                                filtered_cities[city] = content
                                
                        # For other activities, use activity-specific checks
                        elif primary_activity == 'spa_wellness':
                            spa_keywords = ['—Å–ø–∞', '–º–∞—Å—Å–∞–∂', '–≤–µ–ª–Ω–µ—Å', 'wellness', '—Å–∞–Ω–∞—Ç–æ—Ä–∏', '–æ–∑–¥–æ—Ä–æ–≤–∏—Ç', 
                                          '–ª–µ—á–µ–±–Ω', '–∫—É—Ä–æ—Ä—Ç', '–æ—Ç–¥—ã—Ö', '–ø—Ä–æ—Ü–µ–¥—É—Ä', '—Ä–µ–ª–∞–∫—Å', '—Ç–µ—Ä–º–∞–ª—å–Ω',
                                          '–∏—Å—Ç–æ—á–Ω–∏–∫', '–≥—Ä—è–∑–µ–ª–µ—á–µ–Ω–∏', '–º–∏–Ω–µ—Ä–∞–ª—å–Ω', '–Ω–∞—Ä–∑–∞–Ω', '–±—é–≤–µ—Ç']
                            if any(kw in city_text for kw in spa_keywords) or \
                               city in Config.RESORT_CITIES.get('spa', []) or \
                               city in ['–ö–∏—Å–ª–æ–≤–æ–¥—Å–∫', '–ü—è—Ç–∏–≥–æ—Ä—Å–∫', '–ï—Å—Å–µ–Ω—Ç—É–∫–∏', '–ñ–µ–ª–µ–∑–Ω–æ–≤–æ–¥—Å–∫']:
                                filtered_cities[city] = content
                                
                        elif primary_activity == 'winter_sports':
                            if any(kw in city_text for kw in ['–≥–æ—Ä–Ω–æ–ª—ã–∂', '–ª—ã–∂', '–ø–æ–¥—ä–µ–º–Ω–∏–∫', '—Ç—Ä–∞—Å—Å', '—Å–∫–ª–æ–Ω', '–∑–∏–º–Ω']):
                                filtered_cities[city] = content
                                
                        elif primary_activity == 'cultural_tourism':
                            if any(kw in city_text for kw in ['–º—É–∑–µ', '–ø–∞–º—è—Ç–Ω–∏–∫', '–¥–æ—Å—Ç–æ–ø—Ä–∏–º–µ—á–∞—Ç–µ–ª—å–Ω–æ—Å—Ç', '–∏—Å—Ç–æ—Ä–∏', '–∫—É–ª—å—Ç—É—Ä']):
                                filtered_cities[city] = content
                                
                        else:  # Default case for other activities
                            filtered_cities[city] = content
                            
                if filtered_cities:  # Only update if we found matching cities
                    cities_content = filtered_cities
                    print(f"Found {len(cities_content)} cities matching activity and infrastructure criteria")
            
            # Apply seasonal filtering with preferences
            cities_content = self._filter_cities_by_season(cities_content, season, preferences)
            print(f"Found {len(cities_content)} cities matching all criteria")

            # Prepare embeddings
            summaries = [content.summary for content in cities_content.values()]
            summaries.append(preferences)
            print(f"Total summaries to embed: {len(summaries)}")

            # Get embeddings
            all_embeddings = self.embedding_service.get_embeddings_batch(summaries)

            # Separate embeddings
            preferences_embedding = all_embeddings[preferences]
            cities_embeddings = {
                city: all_embeddings[content.summary]
                for city, content in cities_content.items()
            }

            print("Finding top cities")
            top_cities = self.embedding_service.get_top_cities(
                preferences_embedding,
                cities_embeddings,
                {k: v.summary for k, v in cities_content.items()},
                top_n=3,
                season=season,
                activity=primary_activity,
                activity_matcher=self.activity_matcher
            )

            selected_cities = [city for city, _ in top_cities]
            cities_chunks = {
                city: cities_content[city].chunks 
                for city in selected_cities 
                if city in cities_content
            }

            # Find relevant facts for all cities at once
            relevant_facts = {}
            all_city_facts = []
            
            # First collect top facts for all cities
            for city in selected_cities:
                if city in self.fact_embeddings:
                    city_facts = []
                    for category, facts in self.fact_embeddings[city].items():
                        for fact, fact_embedding in facts:
                            similarity = self.embedding_service.cosine_similarity(
                                preferences_embedding.reshape(1, -1),
                                fact_embedding.reshape(1, -1)
                            )[0][0]
                            city_facts.append((fact, similarity))
                    
                    # Sort facts by relevance and take top 15
                    city_facts.sort(key=lambda x: x[1], reverse=True)
                    top_facts = city_facts[:15]
                    facts_text = "\n".join([fact for fact, _ in top_facts])
                    all_city_facts.append({
                        "city": city,
                        "facts": facts_text
                    })
            
            if all_city_facts:
                # Process each city's facts in parallel
                async def summarize_city_facts(city_data):
                    messages = [
                        {"role": "system", "content": f"""–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ —Ñ–∞–∫—Ç–æ–≤ –æ –≥–æ—Ä–æ–¥–µ, –≤—ã–±–µ—Ä–∏—Ç–µ –∏ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π—Ç–µ 5-7 —Å–∞–º—ã—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤.
–ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {preferences}

–ü—Ä–∞–≤–∏–ª–∞:
1. –í—ã–±–∏—Ä–∞–π—Ç–µ —Ñ–∞–∫—Ç—ã, –Ω–∞–ø—Ä—è–º—É—é —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –∏–Ω—Ç–µ—Ä–µ—Å–∞–º–∏ –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
2. –û–±—ä–µ–¥–∏–Ω—è–π—Ç–µ –ø–æ—Ö–æ–∂–∏–µ —Ñ–∞–∫—Ç—ã
3. –£–¥–∞–ª—è–π—Ç–µ –∏–∑–±—ã—Ç–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
4. –§–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ —Ñ–∞–∫—Ç—ã –∫—Ä–∞—Ç–∫–æ –∏ —á–µ—Ç–∫–æ
5. –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ —Ç–æ–ª—å–∫–æ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø–æ–ª–µ–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–µ–∑–¥–∫–∏"""},
                        {"role": "user", "content": city_data["facts"]}
                    ]
                    
                    response = await self.llm_service.client.chat.completions.create(
                        model=Config.LLM_MODEL,
                        messages=messages,
                        temperature=0.0,
                        max_tokens=512
                    )
                    
                    return city_data["city"], [
                        (fact.strip(), 1.0) 
                        for fact in response.choices[0].message.content.split('\n')
                        if fact.strip()
                    ]
                
                # Create tasks for all cities
                tasks = [summarize_city_facts(city_data) for city_data in all_city_facts]
                
                # Run all tasks in parallel
                results = await asyncio.gather(*tasks)
                
                # Organize results
                relevant_facts = {city: facts for city, facts in results}

            # Final LLM summarization of recommendations
            summarized_facts = {}
            for city, facts in relevant_facts.items():
                messages = [
                    {"role": "system", "content": f"""–°–æ–∑–¥–∞–π—Ç–µ –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞, –≤–∫–ª—é—á–∞—è —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞:

–û–°–ù–û–í–ù–´–ï –§–ê–ö–¢–´:
‚Ä¢ –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–µ –≥–æ—Ä–æ–¥–∞
‚Ä¢ –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –¥–ª—è –∑–∞–ø—Ä–æ—à–µ–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞ –æ—Ç–¥—ã—Ö–∞
‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≥–æ—Ä–æ–¥–∞

–ï—Å–ª–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ —É–∫–∞–∑–∞–Ω —Å–µ–∑–æ–Ω:
–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≤ [—Å–µ–∑–æ–Ω]: XX¬∞C

–î–ª—è –ø–ª—è–∂–Ω–æ–≥–æ –æ—Ç–¥—ã—Ö–∞ - —Ç–æ–ª—å–∫–æ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –ø–ª—è–∂–∏:
‚Ä¢ [–Ω–∞–∑–≤–∞–Ω–∏–µ –ø–ª—è–∂–∞]
‚Ä¢ [–Ω–∞–∑–≤–∞–Ω–∏–µ –ø–ª—è–∂–∞]

–î–ª—è —Å–µ–º–µ–π–Ω–æ–≥–æ –æ—Ç–¥—ã—Ö–∞ - —Ç–æ–ª—å–∫–æ —Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–ª—è –¥–µ—Ç–µ–π:
‚Ä¢ [–Ω–∞–∑–≤–∞–Ω–∏–µ –º–µ—Å—Ç–∞]
‚Ä¢ [–Ω–∞–∑–≤–∞–Ω–∏–µ –º–µ—Å—Ç–∞]

–î–ª—è –∫—É–ª—å—Ç—É—Ä–Ω–æ–≥–æ —Ç—É—Ä–∏–∑–º–∞ - —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–æ—Å—Ç–æ–ø—Ä–∏–º–µ—á–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:
‚Ä¢ [–Ω–∞–∑–≤–∞–Ω–∏–µ –º–µ—Å—Ç–∞]
‚Ä¢ [–Ω–∞–∑–≤–∞–Ω–∏–µ –º–µ—Å—Ç–∞]

–î–ª—è –∑–∏–º–Ω–µ–≥–æ –æ—Ç–¥—ã—Ö–∞ - —Ç–æ–ª—å–∫–æ –≥–æ—Ä–Ω–æ–ª—ã–∂–Ω–∞—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞:
‚Ä¢ [–Ω–∞–∑–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞]
‚Ä¢ [–Ω–∞–∑–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞]

–î–ª—è –æ–∑–¥–æ—Ä–æ–≤–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ—Ç–¥—ã—Ö–∞ - —Ç–æ–ª—å–∫–æ —Å–ø–∞ –∏ —Å–∞–Ω–∞—Ç–æ—Ä–∏–∏:
‚Ä¢ [–Ω–∞–∑–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞]
‚Ä¢ [–Ω–∞–∑–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞]

–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {preferences}"""},
                    {"role": "user", "content": "\n".join([fact for fact, _ in facts])}
                ]
                
                response = await self.llm_service.client.chat.completions.create(
                    model=Config.LLM_MODEL,
                    messages=messages,
                    temperature=0.0,
                    max_tokens=256
                )
                
                summarized_facts[city] = [(fact.strip(), 1.0) for fact in response.choices[0].message.content.split('\n') if fact.strip()]

            return cities_chunks, top_cities, preferences, available_tokens, summarized_facts

        except Exception as e:
            print(f"Error occurred in process_request: {str(e)}")
            print(f"Error type: {type(e)}")
            raise
